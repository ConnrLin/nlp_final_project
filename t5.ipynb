{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 14732\n",
      "Test dataset size: 819\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset('samsum')\n",
    "\n",
    "print(f\"Train dataset size: {len(dataset['train'])}\")\n",
    "print(f\"Test dataset size: {len(dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialogue: \n",
      "Ethan: Which gas station has the best prices?\n",
      "Alice: I always tank at the Tesco \n",
      "Sara: Which one?\n",
      "Alice: The one out of town\n",
      "Sara: I heard they have cheap gas there\n",
      "Alice: It's always few cents per litre cheaper\n",
      "Ethan: Good to know. Thanks!! \n",
      "---------------\n",
      "summary: \n",
      "The Tesco that's out of town has the cheapest gas according to Alice and Sara.\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "from random import randrange        \n",
    "\n",
    "\n",
    "sample = dataset['train'][randrange(len(dataset[\"train\"]))]\n",
    "print(f\"dialogue: \\n{sample['dialogue']}\\n---------------\")\n",
    "print(f\"summary: \\n{sample['summary']}\\n---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id=\"google/flan-t5-small\"\n",
    "\n",
    "# Load tokenizer of FLAN-t5-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 512\n",
      "Max target length: 95\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "# The maximum total input sequence length after tokenization. \n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
    "tokenized_inputs = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"dialogue\"], truncation=True), batched=True, remove_columns=[\"dialogue\", \"summary\"])\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "# The maximum total sequence length for target text after tokenization. \n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
    "tokenized_targets = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"summary\"], truncation=True), batched=True, remove_columns=[\"dialogue\", \"summary\"])\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "print(f\"Max target length: {max_target_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8564ad7bec1940b08dbe081be01afabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(sample,padding=\"max_length\"):\n",
    "    # add prefix to the input for t5\n",
    "    inputs = [\"summarize: \" + item for item in sample[\"dialogue\"]]\n",
    "\n",
    "    # tokenize inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Tokenize targets with the `text_target` keyword argument\n",
    "    labels = tokenizer(text_target=sample[\"summary\"], max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=[\"dialogue\", \"summary\", \"id\"])\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "# load model from the hub\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\linha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Metric\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# helper function to postprocess text\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# we want to ignore tokenizer pad token in the loss\n",
    "label_pad_token_id = -100\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "# Hugging Face repository id\n",
    "repository_id = f\"{model_id.split('/')[1]}-{'samsum'}\"\n",
    "\n",
    "# Define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16 = False, # Overflows with fp16\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=10,\n",
    "    # logging & evaluation strategies\n",
    "    logging_dir=f\"{repository_id}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    # metric_for_best_model=\"overall_f1\",\n",
    "    # push to hub parameters\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7c6f67e1e640ee8f7b5735dfdf0f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9209, 'learning_rate': 4.993212055389628e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9404, 'learning_rate': 4.986424110779257e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9285, 'learning_rate': 4.9796361661688847e-05, 'epoch': 0.04}\n",
      "{'loss': 1.7874, 'learning_rate': 4.972848221558512e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8714, 'learning_rate': 4.96606027694814e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8926, 'learning_rate': 4.9592723323377684e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7895, 'learning_rate': 4.952484387727396e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8691, 'learning_rate': 4.945696443117024e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8162, 'learning_rate': 4.938908498506653e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8048, 'learning_rate': 4.932120553896281e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8271, 'learning_rate': 4.9253326092859086e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8404, 'learning_rate': 4.9185446646755365e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8631, 'learning_rate': 4.9117567200651645e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8776, 'learning_rate': 4.9049687754547924e-05, 'epoch': 0.19}\n",
      "{'loss': 1.7901, 'learning_rate': 4.89818083084442e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8076, 'learning_rate': 4.891392886234049e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8181, 'learning_rate': 4.884604941623677e-05, 'epoch': 0.23}\n",
      "{'loss': 1.7313, 'learning_rate': 4.877816997013305e-05, 'epoch': 0.24}\n",
      "{'loss': 1.8867, 'learning_rate': 4.8710290524029326e-05, 'epoch': 0.26}\n",
      "{'loss': 1.7915, 'learning_rate': 4.8642411077925605e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8085, 'learning_rate': 4.8574531631821884e-05, 'epoch': 0.29}\n",
      "{'loss': 1.7777, 'learning_rate': 4.8506652185718163e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8605, 'learning_rate': 4.843877273961445e-05, 'epoch': 0.31}\n",
      "{'loss': 1.7709, 'learning_rate': 4.837089329351073e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8636, 'learning_rate': 4.830301384740701e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9031, 'learning_rate': 4.823513440130329e-05, 'epoch': 0.35}\n",
      "{'loss': 1.7943, 'learning_rate': 4.816725495519957e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8177, 'learning_rate': 4.8099375509095845e-05, 'epoch': 0.38}\n",
      "{'loss': 1.7772, 'learning_rate': 4.8031496062992124e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7655, 'learning_rate': 4.796361661688841e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8458, 'learning_rate': 4.789573717078469e-05, 'epoch': 0.42}\n",
      "{'loss': 1.7977, 'learning_rate': 4.782785772468097e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8328, 'learning_rate': 4.775997827857725e-05, 'epoch': 0.45}\n",
      "{'loss': 1.7495, 'learning_rate': 4.769209883247353e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8922, 'learning_rate': 4.762421938636981e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8176, 'learning_rate': 4.7556339940266085e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8069, 'learning_rate': 4.748846049416237e-05, 'epoch': 0.5}\n",
      "{'loss': 1.821, 'learning_rate': 4.742058104805865e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7899, 'learning_rate': 4.735270160195493e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8518, 'learning_rate': 4.728482215585121e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8034, 'learning_rate': 4.7216942709747494e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8024, 'learning_rate': 4.714906326364377e-05, 'epoch': 0.57}\n",
      "{'loss': 1.7202, 'learning_rate': 4.708118381754005e-05, 'epoch': 0.58}\n",
      "{'loss': 1.9397, 'learning_rate': 4.701330437143633e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8639, 'learning_rate': 4.694542492533261e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8747, 'learning_rate': 4.687754547922889e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7383, 'learning_rate': 4.680966603312517e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8852, 'learning_rate': 4.6741786587021455e-05, 'epoch': 0.65}\n",
      "{'loss': 1.822, 'learning_rate': 4.6673907140917734e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8426, 'learning_rate': 4.660602769481401e-05, 'epoch': 0.68}\n",
      "{'loss': 1.7983, 'learning_rate': 4.653814824871029e-05, 'epoch': 0.69}\n",
      "{'loss': 1.7567, 'learning_rate': 4.647026880260657e-05, 'epoch': 0.71}\n",
      "{'loss': 1.7974, 'learning_rate': 4.640238935650285e-05, 'epoch': 0.72}\n",
      "{'loss': 1.7564, 'learning_rate': 4.633450991039913e-05, 'epoch': 0.73}\n",
      "{'loss': 1.7715, 'learning_rate': 4.6266630464295415e-05, 'epoch': 0.75}\n",
      "{'loss': 1.8523, 'learning_rate': 4.6198751018191694e-05, 'epoch': 0.76}\n",
      "{'loss': 1.7769, 'learning_rate': 4.6130871572087973e-05, 'epoch': 0.77}\n",
      "{'loss': 1.8582, 'learning_rate': 4.606299212598425e-05, 'epoch': 0.79}\n",
      "{'loss': 1.8688, 'learning_rate': 4.599511267988054e-05, 'epoch': 0.8}\n",
      "{'loss': 1.7243, 'learning_rate': 4.592723323377681e-05, 'epoch': 0.81}\n",
      "{'loss': 1.7565, 'learning_rate': 4.585935378767309e-05, 'epoch': 0.83}\n",
      "{'loss': 1.7832, 'learning_rate': 4.5791474341569376e-05, 'epoch': 0.84}\n",
      "{'loss': 1.757, 'learning_rate': 4.5723594895465655e-05, 'epoch': 0.86}\n",
      "{'loss': 1.796, 'learning_rate': 4.5655715449361934e-05, 'epoch': 0.87}\n",
      "{'loss': 1.7321, 'learning_rate': 4.558783600325821e-05, 'epoch': 0.88}\n",
      "{'loss': 1.8002, 'learning_rate': 4.55199565571545e-05, 'epoch': 0.9}\n",
      "{'loss': 1.8276, 'learning_rate': 4.545207711105078e-05, 'epoch': 0.91}\n",
      "{'loss': 1.6908, 'learning_rate': 4.538419766494705e-05, 'epoch': 0.92}\n",
      "{'loss': 1.8028, 'learning_rate': 4.5316318218843336e-05, 'epoch': 0.94}\n",
      "{'loss': 1.7697, 'learning_rate': 4.5248438772739616e-05, 'epoch': 0.95}\n",
      "{'loss': 1.7235, 'learning_rate': 4.5180559326635895e-05, 'epoch': 0.96}\n",
      "{'loss': 1.772, 'learning_rate': 4.5112679880532174e-05, 'epoch': 0.98}\n",
      "{'loss': 1.75, 'learning_rate': 4.504480043442846e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfe08510db14d3f8b09bfd9803140c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6491508483886719, 'eval_rouge1': 43.5063, 'eval_rouge2': 19.2741, 'eval_rougeL': 36.212, 'eval_rougeLsum': 39.6495, 'eval_gen_len': 16.95848595848596, 'eval_runtime': 54.9921, 'eval_samples_per_second': 14.893, 'eval_steps_per_second': 3.728, 'epoch': 1.0}\n",
      "{'loss': 1.7974, 'learning_rate': 4.497692098832474e-05, 'epoch': 1.0}\n",
      "{'loss': 1.7524, 'learning_rate': 4.490904154222102e-05, 'epoch': 1.02}\n",
      "{'loss': 1.734, 'learning_rate': 4.48411620961173e-05, 'epoch': 1.03}\n",
      "{'loss': 1.7572, 'learning_rate': 4.4773282650013576e-05, 'epoch': 1.05}\n",
      "{'loss': 1.7186, 'learning_rate': 4.4705403203909855e-05, 'epoch': 1.06}\n",
      "{'loss': 1.6856, 'learning_rate': 4.4637523757806134e-05, 'epoch': 1.07}\n",
      "{'loss': 1.6907, 'learning_rate': 4.456964431170242e-05, 'epoch': 1.09}\n",
      "{'loss': 1.7638, 'learning_rate': 4.45017648655987e-05, 'epoch': 1.1}\n",
      "{'loss': 1.7183, 'learning_rate': 4.443388541949498e-05, 'epoch': 1.11}\n",
      "{'loss': 1.6803, 'learning_rate': 4.4366005973391264e-05, 'epoch': 1.13}\n",
      "{'loss': 1.7548, 'learning_rate': 4.429812652728754e-05, 'epoch': 1.14}\n",
      "{'loss': 1.7214, 'learning_rate': 4.4230247081183816e-05, 'epoch': 1.15}\n",
      "{'loss': 1.796, 'learning_rate': 4.41623676350801e-05, 'epoch': 1.17}\n",
      "{'loss': 1.6227, 'learning_rate': 4.409448818897638e-05, 'epoch': 1.18}\n",
      "{'loss': 1.745, 'learning_rate': 4.402660874287266e-05, 'epoch': 1.19}\n",
      "{'loss': 1.7233, 'learning_rate': 4.395872929676894e-05, 'epoch': 1.21}\n",
      "{'loss': 1.6919, 'learning_rate': 4.3890849850665225e-05, 'epoch': 1.22}\n",
      "{'loss': 1.708, 'learning_rate': 4.3822970404561504e-05, 'epoch': 1.24}\n",
      "{'loss': 1.7851, 'learning_rate': 4.3755090958457777e-05, 'epoch': 1.25}\n",
      "{'loss': 1.6846, 'learning_rate': 4.368721151235406e-05, 'epoch': 1.26}\n",
      "{'loss': 1.7355, 'learning_rate': 4.361933206625034e-05, 'epoch': 1.28}\n",
      "{'loss': 1.7146, 'learning_rate': 4.355145262014662e-05, 'epoch': 1.29}\n",
      "{'loss': 1.72, 'learning_rate': 4.34835731740429e-05, 'epoch': 1.3}\n",
      "{'loss': 1.7643, 'learning_rate': 4.3415693727939186e-05, 'epoch': 1.32}\n",
      "{'loss': 1.6185, 'learning_rate': 4.3347814281835465e-05, 'epoch': 1.33}\n",
      "{'loss': 1.6821, 'learning_rate': 4.3279934835731744e-05, 'epoch': 1.34}\n",
      "{'loss': 1.6638, 'learning_rate': 4.321205538962802e-05, 'epoch': 1.36}\n",
      "{'loss': 1.7365, 'learning_rate': 4.31441759435243e-05, 'epoch': 1.37}\n",
      "{'loss': 1.692, 'learning_rate': 4.307629649742058e-05, 'epoch': 1.38}\n",
      "{'loss': 1.7189, 'learning_rate': 4.300841705131686e-05, 'epoch': 1.4}\n",
      "{'loss': 1.8073, 'learning_rate': 4.2940537605213146e-05, 'epoch': 1.41}\n",
      "{'loss': 1.7263, 'learning_rate': 4.2872658159109426e-05, 'epoch': 1.43}\n",
      "{'loss': 1.7136, 'learning_rate': 4.2804778713005705e-05, 'epoch': 1.44}\n",
      "{'loss': 1.6695, 'learning_rate': 4.2736899266901984e-05, 'epoch': 1.45}\n",
      "{'loss': 1.7025, 'learning_rate': 4.266901982079826e-05, 'epoch': 1.47}\n",
      "{'loss': 1.6225, 'learning_rate': 4.260114037469454e-05, 'epoch': 1.48}\n",
      "{'loss': 1.7677, 'learning_rate': 4.253326092859082e-05, 'epoch': 1.49}\n",
      "{'loss': 1.6629, 'learning_rate': 4.246538148248711e-05, 'epoch': 1.51}\n",
      "{'loss': 1.7085, 'learning_rate': 4.2397502036383386e-05, 'epoch': 1.52}\n",
      "{'loss': 1.72, 'learning_rate': 4.2329622590279665e-05, 'epoch': 1.53}\n",
      "{'loss': 1.7756, 'learning_rate': 4.2261743144175944e-05, 'epoch': 1.55}\n",
      "{'loss': 1.6494, 'learning_rate': 4.219386369807223e-05, 'epoch': 1.56}\n",
      "{'loss': 1.7718, 'learning_rate': 4.21259842519685e-05, 'epoch': 1.57}\n",
      "{'loss': 1.6855, 'learning_rate': 4.205810480586478e-05, 'epoch': 1.59}\n",
      "{'loss': 1.6717, 'learning_rate': 4.199022535976107e-05, 'epoch': 1.6}\n",
      "{'loss': 1.7406, 'learning_rate': 4.192234591365735e-05, 'epoch': 1.62}\n",
      "{'loss': 1.6534, 'learning_rate': 4.1854466467553626e-05, 'epoch': 1.63}\n",
      "{'loss': 1.7008, 'learning_rate': 4.1786587021449905e-05, 'epoch': 1.64}\n",
      "{'loss': 1.6773, 'learning_rate': 4.171870757534619e-05, 'epoch': 1.66}\n",
      "{'loss': 1.7172, 'learning_rate': 4.165082812924247e-05, 'epoch': 1.67}\n",
      "{'loss': 1.7481, 'learning_rate': 4.158294868313874e-05, 'epoch': 1.68}\n",
      "{'loss': 1.6838, 'learning_rate': 4.151506923703503e-05, 'epoch': 1.7}\n",
      "{'loss': 1.7297, 'learning_rate': 4.144718979093131e-05, 'epoch': 1.71}\n",
      "{'loss': 1.7093, 'learning_rate': 4.1379310344827587e-05, 'epoch': 1.72}\n",
      "{'loss': 1.6754, 'learning_rate': 4.1311430898723866e-05, 'epoch': 1.74}\n",
      "{'loss': 1.6962, 'learning_rate': 4.124355145262015e-05, 'epoch': 1.75}\n",
      "{'loss': 1.7302, 'learning_rate': 4.117567200651643e-05, 'epoch': 1.76}\n",
      "{'loss': 1.7133, 'learning_rate': 4.110779256041271e-05, 'epoch': 1.78}\n",
      "{'loss': 1.6278, 'learning_rate': 4.103991311430899e-05, 'epoch': 1.79}\n",
      "{'loss': 1.6697, 'learning_rate': 4.097203366820527e-05, 'epoch': 1.81}\n",
      "{'loss': 1.7201, 'learning_rate': 4.090415422210155e-05, 'epoch': 1.82}\n",
      "{'loss': 1.7121, 'learning_rate': 4.0836274775997826e-05, 'epoch': 1.83}\n",
      "{'loss': 1.6766, 'learning_rate': 4.076839532989411e-05, 'epoch': 1.85}\n",
      "{'loss': 1.6891, 'learning_rate': 4.070051588379039e-05, 'epoch': 1.86}\n",
      "{'loss': 1.7445, 'learning_rate': 4.063263643768667e-05, 'epoch': 1.87}\n",
      "{'loss': 1.6893, 'learning_rate': 4.056475699158295e-05, 'epoch': 1.89}\n",
      "{'loss': 1.7347, 'learning_rate': 4.049687754547923e-05, 'epoch': 1.9}\n",
      "{'loss': 1.7372, 'learning_rate': 4.042899809937551e-05, 'epoch': 1.91}\n",
      "{'loss': 1.6583, 'learning_rate': 4.036111865327179e-05, 'epoch': 1.93}\n",
      "{'loss': 1.7272, 'learning_rate': 4.029323920716807e-05, 'epoch': 1.94}\n",
      "{'loss': 1.7272, 'learning_rate': 4.022535976106435e-05, 'epoch': 1.95}\n",
      "{'loss': 1.6735, 'learning_rate': 4.015748031496063e-05, 'epoch': 1.97}\n",
      "{'loss': 1.6513, 'learning_rate': 4.008960086885691e-05, 'epoch': 1.98}\n",
      "{'loss': 1.6843, 'learning_rate': 4.0021721422753196e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07387a502f16451ea1b79380d499adb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6354368925094604, 'eval_rouge1': 43.1225, 'eval_rouge2': 19.2661, 'eval_rougeL': 36.0203, 'eval_rougeLsum': 39.2956, 'eval_gen_len': 16.532356532356534, 'eval_runtime': 55.9297, 'eval_samples_per_second': 14.643, 'eval_steps_per_second': 3.665, 'epoch': 2.0}\n",
      "{'loss': 1.6372, 'learning_rate': 3.995384197664947e-05, 'epoch': 2.01}\n",
      "{'loss': 1.6198, 'learning_rate': 3.988596253054575e-05, 'epoch': 2.02}\n",
      "{'loss': 1.707, 'learning_rate': 3.9818083084442033e-05, 'epoch': 2.04}\n",
      "{'loss': 1.654, 'learning_rate': 3.975020363833831e-05, 'epoch': 2.05}\n",
      "{'loss': 1.586, 'learning_rate': 3.968232419223459e-05, 'epoch': 2.06}\n",
      "{'loss': 1.7352, 'learning_rate': 3.961444474613088e-05, 'epoch': 2.08}\n",
      "{'loss': 1.7057, 'learning_rate': 3.954656530002716e-05, 'epoch': 2.09}\n",
      "{'loss': 1.6854, 'learning_rate': 3.9478685853923436e-05, 'epoch': 2.1}\n",
      "{'loss': 1.7343, 'learning_rate': 3.941080640781971e-05, 'epoch': 2.12}\n",
      "{'loss': 1.6417, 'learning_rate': 3.9342926961715994e-05, 'epoch': 2.13}\n",
      "{'loss': 1.6857, 'learning_rate': 3.927504751561227e-05, 'epoch': 2.14}\n",
      "{'loss': 1.6067, 'learning_rate': 3.920716806950855e-05, 'epoch': 2.16}\n",
      "{'loss': 1.669, 'learning_rate': 3.913928862340484e-05, 'epoch': 2.17}\n",
      "{'loss': 1.6971, 'learning_rate': 3.907140917730112e-05, 'epoch': 2.19}\n",
      "{'loss': 1.6961, 'learning_rate': 3.9003529731197397e-05, 'epoch': 2.2}\n",
      "{'loss': 1.6363, 'learning_rate': 3.8935650285093676e-05, 'epoch': 2.21}\n",
      "{'loss': 1.7004, 'learning_rate': 3.8867770838989955e-05, 'epoch': 2.23}\n",
      "{'loss': 1.5844, 'learning_rate': 3.8799891392886234e-05, 'epoch': 2.24}\n",
      "{'loss': 1.6332, 'learning_rate': 3.873201194678251e-05, 'epoch': 2.25}\n",
      "{'loss': 1.619, 'learning_rate': 3.86641325006788e-05, 'epoch': 2.27}\n",
      "{'loss': 1.6116, 'learning_rate': 3.859625305457508e-05, 'epoch': 2.28}\n",
      "{'loss': 1.5335, 'learning_rate': 3.852837360847136e-05, 'epoch': 2.29}\n",
      "{'loss': 1.6816, 'learning_rate': 3.8460494162367636e-05, 'epoch': 2.31}\n",
      "{'loss': 1.5998, 'learning_rate': 3.839261471626392e-05, 'epoch': 2.32}\n",
      "{'loss': 1.6953, 'learning_rate': 3.8324735270160195e-05, 'epoch': 2.34}\n",
      "{'loss': 1.6643, 'learning_rate': 3.8256855824056474e-05, 'epoch': 2.35}\n",
      "{'loss': 1.6466, 'learning_rate': 3.818897637795276e-05, 'epoch': 2.36}\n",
      "{'loss': 1.7164, 'learning_rate': 3.812109693184904e-05, 'epoch': 2.38}\n",
      "{'loss': 1.637, 'learning_rate': 3.805321748574532e-05, 'epoch': 2.39}\n",
      "{'loss': 1.6425, 'learning_rate': 3.79853380396416e-05, 'epoch': 2.4}\n",
      "{'loss': 1.6144, 'learning_rate': 3.791745859353788e-05, 'epoch': 2.42}\n",
      "{'loss': 1.6298, 'learning_rate': 3.784957914743416e-05, 'epoch': 2.43}\n",
      "{'loss': 1.689, 'learning_rate': 3.7781699701330434e-05, 'epoch': 2.44}\n",
      "{'loss': 1.6267, 'learning_rate': 3.771382025522672e-05, 'epoch': 2.46}\n",
      "{'loss': 1.6795, 'learning_rate': 3.7645940809123e-05, 'epoch': 2.47}\n",
      "{'loss': 1.7, 'learning_rate': 3.757806136301928e-05, 'epoch': 2.48}\n",
      "{'loss': 1.7317, 'learning_rate': 3.751018191691556e-05, 'epoch': 2.5}\n",
      "{'loss': 1.5948, 'learning_rate': 3.7442302470811843e-05, 'epoch': 2.51}\n",
      "{'loss': 1.645, 'learning_rate': 3.737442302470812e-05, 'epoch': 2.53}\n",
      "{'loss': 1.5761, 'learning_rate': 3.73065435786044e-05, 'epoch': 2.54}\n",
      "{'loss': 1.5961, 'learning_rate': 3.723866413250068e-05, 'epoch': 2.55}\n",
      "{'loss': 1.5817, 'learning_rate': 3.717078468639696e-05, 'epoch': 2.57}\n",
      "{'loss': 1.5816, 'learning_rate': 3.710290524029324e-05, 'epoch': 2.58}\n",
      "{'loss': 1.5802, 'learning_rate': 3.703502579418952e-05, 'epoch': 2.59}\n",
      "{'loss': 1.6663, 'learning_rate': 3.6967146348085804e-05, 'epoch': 2.61}\n",
      "{'loss': 1.6802, 'learning_rate': 3.689926690198208e-05, 'epoch': 2.62}\n",
      "{'loss': 1.6776, 'learning_rate': 3.683138745587836e-05, 'epoch': 2.63}\n",
      "{'loss': 1.665, 'learning_rate': 3.676350800977464e-05, 'epoch': 2.65}\n",
      "{'loss': 1.6709, 'learning_rate': 3.669562856367092e-05, 'epoch': 2.66}\n",
      "{'loss': 1.6243, 'learning_rate': 3.66277491175672e-05, 'epoch': 2.67}\n",
      "{'loss': 1.691, 'learning_rate': 3.655986967146348e-05, 'epoch': 2.69}\n",
      "{'loss': 1.6586, 'learning_rate': 3.6491990225359765e-05, 'epoch': 2.7}\n",
      "{'loss': 1.5672, 'learning_rate': 3.6424110779256044e-05, 'epoch': 2.72}\n",
      "{'loss': 1.5858, 'learning_rate': 3.635623133315232e-05, 'epoch': 2.73}\n",
      "{'loss': 1.6836, 'learning_rate': 3.62883518870486e-05, 'epoch': 2.74}\n",
      "{'loss': 1.7368, 'learning_rate': 3.622047244094489e-05, 'epoch': 2.76}\n",
      "{'loss': 1.6159, 'learning_rate': 3.615259299484116e-05, 'epoch': 2.77}\n",
      "{'loss': 1.6197, 'learning_rate': 3.608471354873744e-05, 'epoch': 2.78}\n",
      "{'loss': 1.6197, 'learning_rate': 3.6016834102633725e-05, 'epoch': 2.8}\n",
      "{'loss': 1.6156, 'learning_rate': 3.5948954656530004e-05, 'epoch': 2.81}\n",
      "{'loss': 1.5753, 'learning_rate': 3.5881075210426284e-05, 'epoch': 2.82}\n",
      "{'loss': 1.6419, 'learning_rate': 3.581319576432256e-05, 'epoch': 2.84}\n",
      "{'loss': 1.6052, 'learning_rate': 3.574531631821885e-05, 'epoch': 2.85}\n",
      "{'loss': 1.6042, 'learning_rate': 3.567743687211513e-05, 'epoch': 2.86}\n",
      "{'loss': 1.6936, 'learning_rate': 3.56095574260114e-05, 'epoch': 2.88}\n",
      "{'loss': 1.6299, 'learning_rate': 3.5541677979907686e-05, 'epoch': 2.89}\n",
      "{'loss': 1.6298, 'learning_rate': 3.5473798533803965e-05, 'epoch': 2.91}\n",
      "{'loss': 1.6055, 'learning_rate': 3.5405919087700244e-05, 'epoch': 2.92}\n",
      "{'loss': 1.6122, 'learning_rate': 3.533803964159652e-05, 'epoch': 2.93}\n",
      "{'loss': 1.6902, 'learning_rate': 3.527016019549281e-05, 'epoch': 2.95}\n",
      "{'loss': 1.6497, 'learning_rate': 3.520228074938909e-05, 'epoch': 2.96}\n",
      "{'loss': 1.57, 'learning_rate': 3.513440130328537e-05, 'epoch': 2.97}\n",
      "{'loss': 1.6137, 'learning_rate': 3.506652185718165e-05, 'epoch': 2.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16b34edbd12459885d82dd882dd05e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6240123510360718, 'eval_rouge1': 43.0724, 'eval_rouge2': 19.4419, 'eval_rougeL': 35.9736, 'eval_rougeLsum': 39.4537, 'eval_gen_len': 16.67032967032967, 'eval_runtime': 135.7165, 'eval_samples_per_second': 6.035, 'eval_steps_per_second': 1.511, 'epoch': 3.0}\n",
      "{'loss': 1.6287, 'learning_rate': 3.4998642411077926e-05, 'epoch': 3.0}\n",
      "{'loss': 1.6522, 'learning_rate': 3.4930762964974205e-05, 'epoch': 3.01}\n",
      "{'loss': 1.6321, 'learning_rate': 3.4862883518870484e-05, 'epoch': 3.03}\n",
      "{'loss': 1.601, 'learning_rate': 3.479500407276677e-05, 'epoch': 3.04}\n",
      "{'loss': 1.5625, 'learning_rate': 3.472712462666305e-05, 'epoch': 3.05}\n",
      "{'loss': 1.5314, 'learning_rate': 3.465924518055933e-05, 'epoch': 3.07}\n",
      "{'loss': 1.5877, 'learning_rate': 3.4591365734455614e-05, 'epoch': 3.08}\n",
      "{'loss': 1.5271, 'learning_rate': 3.4523486288351886e-05, 'epoch': 3.1}\n",
      "{'loss': 1.6178, 'learning_rate': 3.4455606842248166e-05, 'epoch': 3.11}\n",
      "{'loss': 1.6185, 'learning_rate': 3.4387727396144445e-05, 'epoch': 3.12}\n",
      "{'loss': 1.578, 'learning_rate': 3.431984795004073e-05, 'epoch': 3.14}\n",
      "{'loss': 1.6035, 'learning_rate': 3.425196850393701e-05, 'epoch': 3.15}\n",
      "{'loss': 1.5639, 'learning_rate': 3.418408905783329e-05, 'epoch': 3.16}\n",
      "{'loss': 1.5715, 'learning_rate': 3.4116209611729575e-05, 'epoch': 3.18}\n",
      "{'loss': 1.5731, 'learning_rate': 3.4048330165625854e-05, 'epoch': 3.19}\n",
      "{'loss': 1.5901, 'learning_rate': 3.3980450719522126e-05, 'epoch': 3.2}\n",
      "{'loss': 1.6384, 'learning_rate': 3.3912571273418405e-05, 'epoch': 3.22}\n",
      "{'loss': 1.6207, 'learning_rate': 3.384469182731469e-05, 'epoch': 3.23}\n",
      "{'loss': 1.5758, 'learning_rate': 3.377681238121097e-05, 'epoch': 3.24}\n",
      "{'loss': 1.6311, 'learning_rate': 3.370893293510725e-05, 'epoch': 3.26}\n",
      "{'loss': 1.6108, 'learning_rate': 3.3641053489003535e-05, 'epoch': 3.27}\n",
      "{'loss': 1.5806, 'learning_rate': 3.3573174042899814e-05, 'epoch': 3.29}\n",
      "{'loss': 1.5641, 'learning_rate': 3.3505294596796094e-05, 'epoch': 3.3}\n",
      "{'loss': 1.584, 'learning_rate': 3.343741515069237e-05, 'epoch': 3.31}\n",
      "{'loss': 1.6032, 'learning_rate': 3.336953570458865e-05, 'epoch': 3.33}\n",
      "{'loss': 1.6243, 'learning_rate': 3.330165625848493e-05, 'epoch': 3.34}\n",
      "{'loss': 1.5903, 'learning_rate': 3.323377681238121e-05, 'epoch': 3.35}\n",
      "{'loss': 1.6491, 'learning_rate': 3.3165897366277496e-05, 'epoch': 3.37}\n",
      "{'loss': 1.5361, 'learning_rate': 3.3098017920173775e-05, 'epoch': 3.38}\n",
      "{'loss': 1.5967, 'learning_rate': 3.3030138474070054e-05, 'epoch': 3.39}\n",
      "{'loss': 1.5934, 'learning_rate': 3.296225902796633e-05, 'epoch': 3.41}\n",
      "{'loss': 1.6275, 'learning_rate': 3.289437958186261e-05, 'epoch': 3.42}\n",
      "{'loss': 1.6407, 'learning_rate': 3.282650013575889e-05, 'epoch': 3.43}\n",
      "{'loss': 1.6385, 'learning_rate': 3.275862068965517e-05, 'epoch': 3.45}\n",
      "{'loss': 1.6063, 'learning_rate': 3.2690741243551457e-05, 'epoch': 3.46}\n",
      "{'loss': 1.5809, 'learning_rate': 3.2622861797447736e-05, 'epoch': 3.48}\n",
      "{'loss': 1.5663, 'learning_rate': 3.2554982351344015e-05, 'epoch': 3.49}\n",
      "{'loss': 1.5762, 'learning_rate': 3.2487102905240294e-05, 'epoch': 3.5}\n",
      "{'loss': 1.6077, 'learning_rate': 3.241922345913658e-05, 'epoch': 3.52}\n",
      "{'loss': 1.6661, 'learning_rate': 3.235134401303285e-05, 'epoch': 3.53}\n",
      "{'loss': 1.5934, 'learning_rate': 3.228346456692913e-05, 'epoch': 3.54}\n",
      "{'loss': 1.5618, 'learning_rate': 3.221558512082542e-05, 'epoch': 3.56}\n",
      "{'loss': 1.6098, 'learning_rate': 3.2147705674721696e-05, 'epoch': 3.57}\n",
      "{'loss': 1.6413, 'learning_rate': 3.2079826228617975e-05, 'epoch': 3.58}\n",
      "{'loss': 1.5747, 'learning_rate': 3.2011946782514255e-05, 'epoch': 3.6}\n",
      "{'loss': 1.6369, 'learning_rate': 3.194406733641054e-05, 'epoch': 3.61}\n",
      "{'loss': 1.6186, 'learning_rate': 3.187618789030682e-05, 'epoch': 3.62}\n",
      "{'loss': 1.57, 'learning_rate': 3.180830844420309e-05, 'epoch': 3.64}\n",
      "{'loss': 1.577, 'learning_rate': 3.174042899809938e-05, 'epoch': 3.65}\n",
      "{'loss': 1.5664, 'learning_rate': 3.167254955199566e-05, 'epoch': 3.67}\n",
      "{'loss': 1.5946, 'learning_rate': 3.1604670105891936e-05, 'epoch': 3.68}\n",
      "{'loss': 1.6108, 'learning_rate': 3.1536790659788215e-05, 'epoch': 3.69}\n",
      "{'loss': 1.5456, 'learning_rate': 3.14689112136845e-05, 'epoch': 3.71}\n",
      "{'loss': 1.5535, 'learning_rate': 3.140103176758078e-05, 'epoch': 3.72}\n",
      "{'loss': 1.609, 'learning_rate': 3.133315232147706e-05, 'epoch': 3.73}\n",
      "{'loss': 1.6143, 'learning_rate': 3.126527287537334e-05, 'epoch': 3.75}\n",
      "{'loss': 1.649, 'learning_rate': 3.119739342926962e-05, 'epoch': 3.76}\n",
      "{'loss': 1.5947, 'learning_rate': 3.11295139831659e-05, 'epoch': 3.77}\n",
      "{'loss': 1.5576, 'learning_rate': 3.1061634537062176e-05, 'epoch': 3.79}\n",
      "{'loss': 1.6042, 'learning_rate': 3.099375509095846e-05, 'epoch': 3.8}\n",
      "{'loss': 1.6061, 'learning_rate': 3.092587564485474e-05, 'epoch': 3.81}\n",
      "{'loss': 1.6093, 'learning_rate': 3.085799619875102e-05, 'epoch': 3.83}\n",
      "{'loss': 1.524, 'learning_rate': 3.07901167526473e-05, 'epoch': 3.84}\n",
      "{'loss': 1.6183, 'learning_rate': 3.072223730654358e-05, 'epoch': 3.86}\n",
      "{'loss': 1.5715, 'learning_rate': 3.065435786043986e-05, 'epoch': 3.87}\n",
      "{'loss': 1.6194, 'learning_rate': 3.0586478414336137e-05, 'epoch': 3.88}\n",
      "{'loss': 1.5512, 'learning_rate': 3.051859896823242e-05, 'epoch': 3.9}\n",
      "{'loss': 1.5801, 'learning_rate': 3.04507195221287e-05, 'epoch': 3.91}\n",
      "{'loss': 1.643, 'learning_rate': 3.038284007602498e-05, 'epoch': 3.92}\n",
      "{'loss': 1.6225, 'learning_rate': 3.0314960629921263e-05, 'epoch': 3.94}\n",
      "{'loss': 1.5216, 'learning_rate': 3.0247081183817542e-05, 'epoch': 3.95}\n",
      "{'loss': 1.6494, 'learning_rate': 3.0179201737713818e-05, 'epoch': 3.96}\n",
      "{'loss': 1.5948, 'learning_rate': 3.01113222916101e-05, 'epoch': 3.98}\n",
      "{'loss': 1.611, 'learning_rate': 3.004344284550638e-05, 'epoch': 3.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9142df06801145d4bcb4133670b459ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6198571920394897, 'eval_rouge1': 44.1204, 'eval_rouge2': 20.2736, 'eval_rougeL': 36.8841, 'eval_rougeLsum': 40.4502, 'eval_gen_len': 16.605616605616607, 'eval_runtime': 151.8226, 'eval_samples_per_second': 5.394, 'eval_steps_per_second': 1.35, 'epoch': 4.0}\n",
      "{'loss': 1.5812, 'learning_rate': 2.9975563399402662e-05, 'epoch': 4.0}\n",
      "{'loss': 1.558, 'learning_rate': 2.990768395329894e-05, 'epoch': 4.02}\n",
      "{'loss': 1.5103, 'learning_rate': 2.9839804507195224e-05, 'epoch': 4.03}\n",
      "{'loss': 1.573, 'learning_rate': 2.9771925061091503e-05, 'epoch': 4.05}\n",
      "{'loss': 1.5692, 'learning_rate': 2.9704045614987785e-05, 'epoch': 4.06}\n",
      "{'loss': 1.5176, 'learning_rate': 2.963616616888406e-05, 'epoch': 4.07}\n",
      "{'loss': 1.5898, 'learning_rate': 2.956828672278034e-05, 'epoch': 4.09}\n",
      "{'loss': 1.6016, 'learning_rate': 2.9500407276676623e-05, 'epoch': 4.1}\n",
      "{'loss': 1.5455, 'learning_rate': 2.9432527830572902e-05, 'epoch': 4.11}\n",
      "{'loss': 1.5184, 'learning_rate': 2.9364648384469184e-05, 'epoch': 4.13}\n",
      "{'loss': 1.5436, 'learning_rate': 2.9296768938365467e-05, 'epoch': 4.14}\n",
      "{'loss': 1.5106, 'learning_rate': 2.9228889492261746e-05, 'epoch': 4.15}\n",
      "{'loss': 1.5334, 'learning_rate': 2.916101004615803e-05, 'epoch': 4.17}\n",
      "{'loss': 1.5775, 'learning_rate': 2.90931306000543e-05, 'epoch': 4.18}\n",
      "{'loss': 1.5679, 'learning_rate': 2.9025251153950583e-05, 'epoch': 4.19}\n",
      "{'loss': 1.4709, 'learning_rate': 2.8957371707846863e-05, 'epoch': 4.21}\n",
      "{'loss': 1.6123, 'learning_rate': 2.8889492261743145e-05, 'epoch': 4.22}\n",
      "{'loss': 1.553, 'learning_rate': 2.8821612815639428e-05, 'epoch': 4.24}\n",
      "{'loss': 1.5424, 'learning_rate': 2.8753733369535707e-05, 'epoch': 4.25}\n",
      "{'loss': 1.5882, 'learning_rate': 2.868585392343199e-05, 'epoch': 4.26}\n",
      "{'loss': 1.6097, 'learning_rate': 2.861797447732827e-05, 'epoch': 4.28}\n",
      "{'loss': 1.5041, 'learning_rate': 2.8550095031224544e-05, 'epoch': 4.29}\n",
      "{'loss': 1.5245, 'learning_rate': 2.8482215585120827e-05, 'epoch': 4.3}\n",
      "{'loss': 1.5746, 'learning_rate': 2.8414336139017106e-05, 'epoch': 4.32}\n",
      "{'loss': 1.5376, 'learning_rate': 2.8346456692913388e-05, 'epoch': 4.33}\n",
      "{'loss': 1.5525, 'learning_rate': 2.8278577246809667e-05, 'epoch': 4.34}\n",
      "{'loss': 1.5271, 'learning_rate': 2.821069780070595e-05, 'epoch': 4.36}\n",
      "{'loss': 1.5966, 'learning_rate': 2.814281835460223e-05, 'epoch': 4.37}\n",
      "{'loss': 1.5764, 'learning_rate': 2.807493890849851e-05, 'epoch': 4.39}\n",
      "{'loss': 1.542, 'learning_rate': 2.8007059462394787e-05, 'epoch': 4.4}\n",
      "{'loss': 1.5148, 'learning_rate': 2.7939180016291066e-05, 'epoch': 4.41}\n",
      "{'loss': 1.5584, 'learning_rate': 2.787130057018735e-05, 'epoch': 4.43}\n",
      "{'loss': 1.5931, 'learning_rate': 2.7803421124083628e-05, 'epoch': 4.44}\n",
      "{'loss': 1.6022, 'learning_rate': 2.773554167797991e-05, 'epoch': 4.45}\n",
      "{'loss': 1.603, 'learning_rate': 2.766766223187619e-05, 'epoch': 4.47}\n",
      "{'loss': 1.5016, 'learning_rate': 2.7599782785772472e-05, 'epoch': 4.48}\n",
      "{'loss': 1.5478, 'learning_rate': 2.753190333966875e-05, 'epoch': 4.49}\n",
      "{'loss': 1.5256, 'learning_rate': 2.7464023893565027e-05, 'epoch': 4.51}\n",
      "{'loss': 1.5369, 'learning_rate': 2.739614444746131e-05, 'epoch': 4.52}\n",
      "{'loss': 1.5392, 'learning_rate': 2.732826500135759e-05, 'epoch': 4.53}\n",
      "{'loss': 1.5941, 'learning_rate': 2.726038555525387e-05, 'epoch': 4.55}\n",
      "{'loss': 1.6163, 'learning_rate': 2.719250610915015e-05, 'epoch': 4.56}\n",
      "{'loss': 1.6125, 'learning_rate': 2.7124626663046433e-05, 'epoch': 4.58}\n",
      "{'loss': 1.5635, 'learning_rate': 2.7056747216942712e-05, 'epoch': 4.59}\n",
      "{'loss': 1.6127, 'learning_rate': 2.6988867770838994e-05, 'epoch': 4.6}\n",
      "{'loss': 1.4827, 'learning_rate': 2.692098832473527e-05, 'epoch': 4.62}\n",
      "{'loss': 1.5714, 'learning_rate': 2.685310887863155e-05, 'epoch': 4.63}\n",
      "{'loss': 1.5357, 'learning_rate': 2.6785229432527832e-05, 'epoch': 4.64}\n",
      "{'loss': 1.4956, 'learning_rate': 2.671734998642411e-05, 'epoch': 4.66}\n",
      "{'loss': 1.5726, 'learning_rate': 2.6649470540320393e-05, 'epoch': 4.67}\n",
      "{'loss': 1.5495, 'learning_rate': 2.6581591094216673e-05, 'epoch': 4.68}\n",
      "{'loss': 1.6274, 'learning_rate': 2.6513711648112955e-05, 'epoch': 4.7}\n",
      "{'loss': 1.5316, 'learning_rate': 2.6445832202009234e-05, 'epoch': 4.71}\n",
      "{'loss': 1.6633, 'learning_rate': 2.637795275590551e-05, 'epoch': 4.72}\n",
      "{'loss': 1.5825, 'learning_rate': 2.6310073309801792e-05, 'epoch': 4.74}\n",
      "{'loss': 1.5302, 'learning_rate': 2.624219386369807e-05, 'epoch': 4.75}\n",
      "{'loss': 1.5653, 'learning_rate': 2.6174314417594354e-05, 'epoch': 4.77}\n",
      "{'loss': 1.5844, 'learning_rate': 2.6106434971490633e-05, 'epoch': 4.78}\n",
      "{'loss': 1.5382, 'learning_rate': 2.6038555525386916e-05, 'epoch': 4.79}\n",
      "{'loss': 1.5487, 'learning_rate': 2.5970676079283195e-05, 'epoch': 4.81}\n",
      "{'loss': 1.5619, 'learning_rate': 2.5902796633179477e-05, 'epoch': 4.82}\n",
      "{'loss': 1.593, 'learning_rate': 2.5834917187075753e-05, 'epoch': 4.83}\n",
      "{'loss': 1.5435, 'learning_rate': 2.5767037740972032e-05, 'epoch': 4.85}\n",
      "{'loss': 1.6047, 'learning_rate': 2.5699158294868315e-05, 'epoch': 4.86}\n",
      "{'loss': 1.5663, 'learning_rate': 2.5631278848764594e-05, 'epoch': 4.87}\n",
      "{'loss': 1.5193, 'learning_rate': 2.5563399402660876e-05, 'epoch': 4.89}\n",
      "{'loss': 1.5322, 'learning_rate': 2.5495519956557155e-05, 'epoch': 4.9}\n",
      "{'loss': 1.5286, 'learning_rate': 2.5427640510453438e-05, 'epoch': 4.91}\n",
      "{'loss': 1.4931, 'learning_rate': 2.5359761064349717e-05, 'epoch': 4.93}\n",
      "{'loss': 1.5818, 'learning_rate': 2.5291881618245993e-05, 'epoch': 4.94}\n",
      "{'loss': 1.6001, 'learning_rate': 2.5224002172142275e-05, 'epoch': 4.96}\n",
      "{'loss': 1.5971, 'learning_rate': 2.5156122726038554e-05, 'epoch': 4.97}\n",
      "{'loss': 1.5841, 'learning_rate': 2.5088243279934837e-05, 'epoch': 4.98}\n",
      "{'loss': 1.4851, 'learning_rate': 2.5020363833831116e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a44360e368e4139a80deec33b69d6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6169418096542358, 'eval_rouge1': 44.153, 'eval_rouge2': 20.1367, 'eval_rougeL': 36.8736, 'eval_rougeLsum': 40.4585, 'eval_gen_len': 16.804639804639805, 'eval_runtime': 56.39, 'eval_samples_per_second': 14.524, 'eval_steps_per_second': 3.635, 'epoch': 5.0}\n",
      "{'loss': 1.5238, 'learning_rate': 2.49524843877274e-05, 'epoch': 5.01}\n",
      "{'loss': 1.4867, 'learning_rate': 2.4884604941623678e-05, 'epoch': 5.02}\n",
      "{'loss': 1.5461, 'learning_rate': 2.4816725495519957e-05, 'epoch': 5.04}\n",
      "{'loss': 1.4787, 'learning_rate': 2.474884604941624e-05, 'epoch': 5.05}\n",
      "{'loss': 1.5038, 'learning_rate': 2.468096660331252e-05, 'epoch': 5.06}\n",
      "{'loss': 1.5701, 'learning_rate': 2.4613087157208798e-05, 'epoch': 5.08}\n",
      "{'loss': 1.4932, 'learning_rate': 2.4545207711105077e-05, 'epoch': 5.09}\n",
      "{'loss': 1.5636, 'learning_rate': 2.447732826500136e-05, 'epoch': 5.1}\n",
      "{'loss': 1.492, 'learning_rate': 2.440944881889764e-05, 'epoch': 5.12}\n",
      "{'loss': 1.4649, 'learning_rate': 2.4341569372793918e-05, 'epoch': 5.13}\n",
      "{'loss': 1.5174, 'learning_rate': 2.42736899266902e-05, 'epoch': 5.15}\n",
      "{'loss': 1.4989, 'learning_rate': 2.420581048058648e-05, 'epoch': 5.16}\n",
      "{'loss': 1.5864, 'learning_rate': 2.413793103448276e-05, 'epoch': 5.17}\n",
      "{'loss': 1.5523, 'learning_rate': 2.4070051588379037e-05, 'epoch': 5.19}\n",
      "{'loss': 1.5479, 'learning_rate': 2.400217214227532e-05, 'epoch': 5.2}\n",
      "{'loss': 1.5113, 'learning_rate': 2.3934292696171602e-05, 'epoch': 5.21}\n",
      "{'loss': 1.6064, 'learning_rate': 2.386641325006788e-05, 'epoch': 5.23}\n",
      "{'loss': 1.603, 'learning_rate': 2.379853380396416e-05, 'epoch': 5.24}\n",
      "{'loss': 1.5457, 'learning_rate': 2.373065435786044e-05, 'epoch': 5.25}\n",
      "{'loss': 1.5053, 'learning_rate': 2.3662774911756722e-05, 'epoch': 5.27}\n",
      "{'loss': 1.5813, 'learning_rate': 2.3594895465653e-05, 'epoch': 5.28}\n",
      "{'loss': 1.4783, 'learning_rate': 2.352701601954928e-05, 'epoch': 5.29}\n",
      "{'loss': 1.4841, 'learning_rate': 2.3459136573445563e-05, 'epoch': 5.31}\n",
      "{'loss': 1.5045, 'learning_rate': 2.3391257127341842e-05, 'epoch': 5.32}\n",
      "{'loss': 1.5259, 'learning_rate': 2.3323377681238125e-05, 'epoch': 5.34}\n",
      "{'loss': 1.5355, 'learning_rate': 2.32554982351344e-05, 'epoch': 5.35}\n",
      "{'loss': 1.5907, 'learning_rate': 2.3187618789030683e-05, 'epoch': 5.36}\n",
      "{'loss': 1.4702, 'learning_rate': 2.3119739342926962e-05, 'epoch': 5.38}\n",
      "{'loss': 1.4665, 'learning_rate': 2.3051859896823245e-05, 'epoch': 5.39}\n",
      "{'loss': 1.5568, 'learning_rate': 2.2983980450719524e-05, 'epoch': 5.4}\n",
      "{'loss': 1.4978, 'learning_rate': 2.2916101004615803e-05, 'epoch': 5.42}\n",
      "{'loss': 1.5322, 'learning_rate': 2.2848221558512085e-05, 'epoch': 5.43}\n",
      "{'loss': 1.4789, 'learning_rate': 2.2780342112408364e-05, 'epoch': 5.44}\n",
      "{'loss': 1.5263, 'learning_rate': 2.2712462666304644e-05, 'epoch': 5.46}\n",
      "{'loss': 1.5256, 'learning_rate': 2.2644583220200923e-05, 'epoch': 5.47}\n",
      "{'loss': 1.485, 'learning_rate': 2.2576703774097205e-05, 'epoch': 5.48}\n",
      "{'loss': 1.5792, 'learning_rate': 2.2508824327993484e-05, 'epoch': 5.5}\n",
      "{'loss': 1.4983, 'learning_rate': 2.2440944881889763e-05, 'epoch': 5.51}\n",
      "{'loss': 1.5911, 'learning_rate': 2.2373065435786046e-05, 'epoch': 5.53}\n",
      "{'loss': 1.5104, 'learning_rate': 2.2305185989682325e-05, 'epoch': 5.54}\n",
      "{'loss': 1.5315, 'learning_rate': 2.2237306543578608e-05, 'epoch': 5.55}\n",
      "{'loss': 1.5733, 'learning_rate': 2.2169427097474883e-05, 'epoch': 5.57}\n",
      "{'loss': 1.5451, 'learning_rate': 2.2101547651371166e-05, 'epoch': 5.58}\n",
      "{'loss': 1.5084, 'learning_rate': 2.2033668205267445e-05, 'epoch': 5.59}\n",
      "{'loss': 1.4789, 'learning_rate': 2.1965788759163727e-05, 'epoch': 5.61}\n",
      "{'loss': 1.4783, 'learning_rate': 2.1897909313060007e-05, 'epoch': 5.62}\n",
      "{'loss': 1.554, 'learning_rate': 2.1830029866956286e-05, 'epoch': 5.63}\n",
      "{'loss': 1.5272, 'learning_rate': 2.1762150420852568e-05, 'epoch': 5.65}\n",
      "{'loss': 1.5189, 'learning_rate': 2.1694270974748847e-05, 'epoch': 5.66}\n",
      "{'loss': 1.4704, 'learning_rate': 2.1626391528645126e-05, 'epoch': 5.67}\n",
      "{'loss': 1.5043, 'learning_rate': 2.1558512082541406e-05, 'epoch': 5.69}\n",
      "{'loss': 1.4919, 'learning_rate': 2.1490632636437688e-05, 'epoch': 5.7}\n",
      "{'loss': 1.4953, 'learning_rate': 2.142275319033397e-05, 'epoch': 5.72}\n",
      "{'loss': 1.5789, 'learning_rate': 2.1354873744230246e-05, 'epoch': 5.73}\n",
      "{'loss': 1.5103, 'learning_rate': 2.128699429812653e-05, 'epoch': 5.74}\n",
      "{'loss': 1.6496, 'learning_rate': 2.1219114852022808e-05, 'epoch': 5.76}\n",
      "{'loss': 1.5619, 'learning_rate': 2.115123540591909e-05, 'epoch': 5.77}\n",
      "{'loss': 1.5614, 'learning_rate': 2.108335595981537e-05, 'epoch': 5.78}\n",
      "{'loss': 1.471, 'learning_rate': 2.101547651371165e-05, 'epoch': 5.8}\n",
      "{'loss': 1.5205, 'learning_rate': 2.094759706760793e-05, 'epoch': 5.81}\n",
      "{'loss': 1.5685, 'learning_rate': 2.087971762150421e-05, 'epoch': 5.82}\n",
      "{'loss': 1.5747, 'learning_rate': 2.081183817540049e-05, 'epoch': 5.84}\n",
      "{'loss': 1.4997, 'learning_rate': 2.074395872929677e-05, 'epoch': 5.85}\n",
      "{'loss': 1.5193, 'learning_rate': 2.067607928319305e-05, 'epoch': 5.86}\n",
      "{'loss': 1.5624, 'learning_rate': 2.060819983708933e-05, 'epoch': 5.88}\n",
      "{'loss': 1.5275, 'learning_rate': 2.054032039098561e-05, 'epoch': 5.89}\n",
      "{'loss': 1.4755, 'learning_rate': 2.0472440944881892e-05, 'epoch': 5.91}\n",
      "{'loss': 1.5205, 'learning_rate': 2.040456149877817e-05, 'epoch': 5.92}\n",
      "{'loss': 1.5098, 'learning_rate': 2.0336682052674454e-05, 'epoch': 5.93}\n",
      "{'loss': 1.5163, 'learning_rate': 2.026880260657073e-05, 'epoch': 5.95}\n",
      "{'loss': 1.5146, 'learning_rate': 2.0200923160467012e-05, 'epoch': 5.96}\n",
      "{'loss': 1.5317, 'learning_rate': 2.013304371436329e-05, 'epoch': 5.97}\n",
      "{'loss': 1.5113, 'learning_rate': 2.0065164268259573e-05, 'epoch': 5.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a88eeda89b4456ca2a8214808191b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6206824779510498, 'eval_rouge1': 44.733, 'eval_rouge2': 20.4625, 'eval_rougeL': 37.1198, 'eval_rougeLsum': 40.871, 'eval_gen_len': 16.978021978021978, 'eval_runtime': 54.0477, 'eval_samples_per_second': 15.153, 'eval_steps_per_second': 3.793, 'epoch': 6.0}\n",
      "{'loss': 1.4734, 'learning_rate': 1.9997284822155853e-05, 'epoch': 6.0}\n",
      "{'loss': 1.501, 'learning_rate': 1.992940537605213e-05, 'epoch': 6.01}\n",
      "{'loss': 1.5319, 'learning_rate': 1.9861525929948414e-05, 'epoch': 6.03}\n",
      "{'loss': 1.4842, 'learning_rate': 1.9793646483844693e-05, 'epoch': 6.04}\n",
      "{'loss': 1.5514, 'learning_rate': 1.9725767037740972e-05, 'epoch': 6.05}\n",
      "{'loss': 1.3935, 'learning_rate': 1.965788759163725e-05, 'epoch': 6.07}\n",
      "{'loss': 1.4688, 'learning_rate': 1.9590008145533534e-05, 'epoch': 6.08}\n",
      "{'loss': 1.4952, 'learning_rate': 1.9522128699429813e-05, 'epoch': 6.1}\n",
      "{'loss': 1.5246, 'learning_rate': 1.9454249253326092e-05, 'epoch': 6.11}\n",
      "{'loss': 1.4749, 'learning_rate': 1.9386369807222375e-05, 'epoch': 6.12}\n",
      "{'loss': 1.5249, 'learning_rate': 1.9318490361118654e-05, 'epoch': 6.14}\n",
      "{'loss': 1.3936, 'learning_rate': 1.9250610915014936e-05, 'epoch': 6.15}\n",
      "{'loss': 1.5317, 'learning_rate': 1.9182731468911212e-05, 'epoch': 6.16}\n",
      "{'loss': 1.5038, 'learning_rate': 1.9114852022807495e-05, 'epoch': 6.18}\n",
      "{'loss': 1.5183, 'learning_rate': 1.9046972576703774e-05, 'epoch': 6.19}\n",
      "{'loss': 1.4781, 'learning_rate': 1.8979093130600056e-05, 'epoch': 6.2}\n",
      "{'loss': 1.5844, 'learning_rate': 1.8911213684496335e-05, 'epoch': 6.22}\n",
      "{'loss': 1.4563, 'learning_rate': 1.8843334238392615e-05, 'epoch': 6.23}\n",
      "{'loss': 1.5574, 'learning_rate': 1.8775454792288897e-05, 'epoch': 6.24}\n",
      "{'loss': 1.5054, 'learning_rate': 1.8707575346185176e-05, 'epoch': 6.26}\n",
      "{'loss': 1.5457, 'learning_rate': 1.8639695900081455e-05, 'epoch': 6.27}\n",
      "{'loss': 1.5394, 'learning_rate': 1.8571816453977738e-05, 'epoch': 6.29}\n",
      "{'loss': 1.4782, 'learning_rate': 1.8503937007874017e-05, 'epoch': 6.3}\n",
      "{'loss': 1.5318, 'learning_rate': 1.84360575617703e-05, 'epoch': 6.31}\n",
      "{'loss': 1.5157, 'learning_rate': 1.8368178115666575e-05, 'epoch': 6.33}\n",
      "{'loss': 1.5375, 'learning_rate': 1.8300298669562858e-05, 'epoch': 6.34}\n",
      "{'loss': 1.6109, 'learning_rate': 1.8232419223459137e-05, 'epoch': 6.35}\n",
      "{'loss': 1.5109, 'learning_rate': 1.816453977735542e-05, 'epoch': 6.37}\n",
      "{'loss': 1.5173, 'learning_rate': 1.80966603312517e-05, 'epoch': 6.38}\n",
      "{'loss': 1.5671, 'learning_rate': 1.8028780885147978e-05, 'epoch': 6.39}\n",
      "{'loss': 1.4584, 'learning_rate': 1.796090143904426e-05, 'epoch': 6.41}\n",
      "{'loss': 1.4496, 'learning_rate': 1.789302199294054e-05, 'epoch': 6.42}\n",
      "{'loss': 1.4857, 'learning_rate': 1.782514254683682e-05, 'epoch': 6.43}\n",
      "{'loss': 1.4762, 'learning_rate': 1.7757263100733097e-05, 'epoch': 6.45}\n",
      "{'loss': 1.4922, 'learning_rate': 1.768938365462938e-05, 'epoch': 6.46}\n",
      "{'loss': 1.4957, 'learning_rate': 1.762150420852566e-05, 'epoch': 6.48}\n",
      "{'loss': 1.5015, 'learning_rate': 1.7553624762421938e-05, 'epoch': 6.49}\n",
      "{'loss': 1.4639, 'learning_rate': 1.748574531631822e-05, 'epoch': 6.5}\n",
      "{'loss': 1.5194, 'learning_rate': 1.74178658702145e-05, 'epoch': 6.52}\n",
      "{'loss': 1.4592, 'learning_rate': 1.7349986424110782e-05, 'epoch': 6.53}\n",
      "{'loss': 1.4512, 'learning_rate': 1.7282106978007058e-05, 'epoch': 6.54}\n",
      "{'loss': 1.4952, 'learning_rate': 1.721422753190334e-05, 'epoch': 6.56}\n",
      "{'loss': 1.4349, 'learning_rate': 1.714634808579962e-05, 'epoch': 6.57}\n",
      "{'loss': 1.5392, 'learning_rate': 1.7078468639695902e-05, 'epoch': 6.58}\n",
      "{'loss': 1.4981, 'learning_rate': 1.701058919359218e-05, 'epoch': 6.6}\n",
      "{'loss': 1.4869, 'learning_rate': 1.694270974748846e-05, 'epoch': 6.61}\n",
      "{'loss': 1.5057, 'learning_rate': 1.6874830301384743e-05, 'epoch': 6.63}\n",
      "{'loss': 1.4728, 'learning_rate': 1.6806950855281022e-05, 'epoch': 6.64}\n",
      "{'loss': 1.5321, 'learning_rate': 1.67390714091773e-05, 'epoch': 6.65}\n",
      "{'loss': 1.5183, 'learning_rate': 1.667119196307358e-05, 'epoch': 6.67}\n",
      "{'loss': 1.4967, 'learning_rate': 1.6603312516969863e-05, 'epoch': 6.68}\n",
      "{'loss': 1.4772, 'learning_rate': 1.6535433070866142e-05, 'epoch': 6.69}\n",
      "{'loss': 1.4153, 'learning_rate': 1.646755362476242e-05, 'epoch': 6.71}\n",
      "{'loss': 1.473, 'learning_rate': 1.6399674178658704e-05, 'epoch': 6.72}\n",
      "{'loss': 1.5506, 'learning_rate': 1.6331794732554983e-05, 'epoch': 6.73}\n",
      "{'loss': 1.5518, 'learning_rate': 1.6263915286451265e-05, 'epoch': 6.75}\n",
      "{'loss': 1.5365, 'learning_rate': 1.619603584034754e-05, 'epoch': 6.76}\n",
      "{'loss': 1.4614, 'learning_rate': 1.6128156394243824e-05, 'epoch': 6.77}\n",
      "{'loss': 1.5142, 'learning_rate': 1.6060276948140106e-05, 'epoch': 6.79}\n",
      "{'loss': 1.5509, 'learning_rate': 1.5992397502036385e-05, 'epoch': 6.8}\n",
      "{'loss': 1.5293, 'learning_rate': 1.5924518055932664e-05, 'epoch': 6.82}\n",
      "{'loss': 1.505, 'learning_rate': 1.5856638609828943e-05, 'epoch': 6.83}\n",
      "{'loss': 1.4825, 'learning_rate': 1.5788759163725226e-05, 'epoch': 6.84}\n",
      "{'loss': 1.541, 'learning_rate': 1.5720879717621505e-05, 'epoch': 6.86}\n",
      "{'loss': 1.5264, 'learning_rate': 1.5653000271517784e-05, 'epoch': 6.87}\n",
      "{'loss': 1.4614, 'learning_rate': 1.5585120825414067e-05, 'epoch': 6.88}\n",
      "{'loss': 1.4541, 'learning_rate': 1.5517241379310346e-05, 'epoch': 6.9}\n",
      "{'loss': 1.5668, 'learning_rate': 1.544936193320663e-05, 'epoch': 6.91}\n",
      "{'loss': 1.5072, 'learning_rate': 1.5381482487102904e-05, 'epoch': 6.92}\n",
      "{'loss': 1.5124, 'learning_rate': 1.5313603040999187e-05, 'epoch': 6.94}\n",
      "{'loss': 1.4895, 'learning_rate': 1.5245723594895467e-05, 'epoch': 6.95}\n",
      "{'loss': 1.5061, 'learning_rate': 1.5177844148791748e-05, 'epoch': 6.96}\n",
      "{'loss': 1.5273, 'learning_rate': 1.5109964702688026e-05, 'epoch': 6.98}\n",
      "{'loss': 1.4923, 'learning_rate': 1.5042085256584306e-05, 'epoch': 6.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d9cd6835154de4ba23538705ca7d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.61181640625, 'eval_rouge1': 44.4626, 'eval_rouge2': 20.3587, 'eval_rougeL': 36.8987, 'eval_rougeLsum': 40.6886, 'eval_gen_len': 16.912087912087912, 'eval_runtime': 56.3581, 'eval_samples_per_second': 14.532, 'eval_steps_per_second': 3.637, 'epoch': 7.0}\n",
      "{'loss': 1.5232, 'learning_rate': 1.4974205810480587e-05, 'epoch': 7.01}\n",
      "{'loss': 1.4667, 'learning_rate': 1.4906326364376868e-05, 'epoch': 7.02}\n",
      "{'loss': 1.4187, 'learning_rate': 1.4838446918273147e-05, 'epoch': 7.03}\n",
      "{'loss': 1.4442, 'learning_rate': 1.4770567472169428e-05, 'epoch': 7.05}\n",
      "{'loss': 1.4759, 'learning_rate': 1.4702688026065709e-05, 'epoch': 7.06}\n",
      "{'loss': 1.5311, 'learning_rate': 1.463480857996199e-05, 'epoch': 7.07}\n",
      "{'loss': 1.451, 'learning_rate': 1.4566929133858267e-05, 'epoch': 7.09}\n",
      "{'loss': 1.5007, 'learning_rate': 1.4499049687754548e-05, 'epoch': 7.1}\n",
      "{'loss': 1.4924, 'learning_rate': 1.4431170241650829e-05, 'epoch': 7.11}\n",
      "{'loss': 1.5019, 'learning_rate': 1.436329079554711e-05, 'epoch': 7.13}\n",
      "{'loss': 1.4942, 'learning_rate': 1.4295411349443389e-05, 'epoch': 7.14}\n",
      "{'loss': 1.4519, 'learning_rate': 1.422753190333967e-05, 'epoch': 7.15}\n",
      "{'loss': 1.4222, 'learning_rate': 1.415965245723595e-05, 'epoch': 7.17}\n",
      "{'loss': 1.506, 'learning_rate': 1.4091773011132231e-05, 'epoch': 7.18}\n",
      "{'loss': 1.5541, 'learning_rate': 1.4023893565028509e-05, 'epoch': 7.2}\n",
      "{'loss': 1.4592, 'learning_rate': 1.395601411892479e-05, 'epoch': 7.21}\n",
      "{'loss': 1.4378, 'learning_rate': 1.388813467282107e-05, 'epoch': 7.22}\n",
      "{'loss': 1.5082, 'learning_rate': 1.3820255226717353e-05, 'epoch': 7.24}\n",
      "{'loss': 1.512, 'learning_rate': 1.375237578061363e-05, 'epoch': 7.25}\n",
      "{'loss': 1.4926, 'learning_rate': 1.3684496334509911e-05, 'epoch': 7.26}\n",
      "{'loss': 1.4918, 'learning_rate': 1.3616616888406192e-05, 'epoch': 7.28}\n",
      "{'loss': 1.402, 'learning_rate': 1.3548737442302473e-05, 'epoch': 7.29}\n",
      "{'loss': 1.4432, 'learning_rate': 1.348085799619875e-05, 'epoch': 7.3}\n",
      "{'loss': 1.4679, 'learning_rate': 1.3412978550095033e-05, 'epoch': 7.32}\n",
      "{'loss': 1.5086, 'learning_rate': 1.3345099103991313e-05, 'epoch': 7.33}\n",
      "{'loss': 1.4744, 'learning_rate': 1.3277219657887594e-05, 'epoch': 7.34}\n",
      "{'loss': 1.4749, 'learning_rate': 1.3209340211783872e-05, 'epoch': 7.36}\n",
      "{'loss': 1.5388, 'learning_rate': 1.3141460765680152e-05, 'epoch': 7.37}\n",
      "{'loss': 1.4238, 'learning_rate': 1.3073581319576433e-05, 'epoch': 7.39}\n",
      "{'loss': 1.4867, 'learning_rate': 1.3005701873472714e-05, 'epoch': 7.4}\n",
      "{'loss': 1.4824, 'learning_rate': 1.2937822427368993e-05, 'epoch': 7.41}\n",
      "{'loss': 1.4768, 'learning_rate': 1.2869942981265274e-05, 'epoch': 7.43}\n",
      "{'loss': 1.4875, 'learning_rate': 1.2802063535161555e-05, 'epoch': 7.44}\n",
      "{'loss': 1.5379, 'learning_rate': 1.2734184089057836e-05, 'epoch': 7.45}\n",
      "{'loss': 1.4982, 'learning_rate': 1.2666304642954113e-05, 'epoch': 7.47}\n",
      "{'loss': 1.4984, 'learning_rate': 1.2598425196850394e-05, 'epoch': 7.48}\n",
      "{'loss': 1.4575, 'learning_rate': 1.2530545750746675e-05, 'epoch': 7.49}\n",
      "{'loss': 1.505, 'learning_rate': 1.2462666304642954e-05, 'epoch': 7.51}\n",
      "{'loss': 1.4745, 'learning_rate': 1.2394786858539235e-05, 'epoch': 7.52}\n",
      "{'loss': 1.4832, 'learning_rate': 1.2326907412435515e-05, 'epoch': 7.53}\n",
      "{'loss': 1.4852, 'learning_rate': 1.2259027966331796e-05, 'epoch': 7.55}\n",
      "{'loss': 1.5403, 'learning_rate': 1.2191148520228075e-05, 'epoch': 7.56}\n",
      "{'loss': 1.414, 'learning_rate': 1.2123269074124356e-05, 'epoch': 7.58}\n",
      "{'loss': 1.5325, 'learning_rate': 1.2055389628020635e-05, 'epoch': 7.59}\n",
      "{'loss': 1.4982, 'learning_rate': 1.1987510181916916e-05, 'epoch': 7.6}\n",
      "{'loss': 1.5477, 'learning_rate': 1.1919630735813197e-05, 'epoch': 7.62}\n",
      "{'loss': 1.5043, 'learning_rate': 1.1851751289709478e-05, 'epoch': 7.63}\n",
      "{'loss': 1.4692, 'learning_rate': 1.1783871843605757e-05, 'epoch': 7.64}\n",
      "{'loss': 1.5052, 'learning_rate': 1.1715992397502038e-05, 'epoch': 7.66}\n",
      "{'loss': 1.5794, 'learning_rate': 1.1648112951398317e-05, 'epoch': 7.67}\n",
      "{'loss': 1.4478, 'learning_rate': 1.1580233505294598e-05, 'epoch': 7.68}\n",
      "{'loss': 1.5151, 'learning_rate': 1.1512354059190877e-05, 'epoch': 7.7}\n",
      "{'loss': 1.471, 'learning_rate': 1.1444474613087158e-05, 'epoch': 7.71}\n",
      "{'loss': 1.4411, 'learning_rate': 1.1376595166983438e-05, 'epoch': 7.72}\n",
      "{'loss': 1.5028, 'learning_rate': 1.130871572087972e-05, 'epoch': 7.74}\n",
      "{'loss': 1.4962, 'learning_rate': 1.1240836274775998e-05, 'epoch': 7.75}\n",
      "{'loss': 1.4694, 'learning_rate': 1.1172956828672279e-05, 'epoch': 7.77}\n",
      "{'loss': 1.4238, 'learning_rate': 1.1105077382568558e-05, 'epoch': 7.78}\n",
      "{'loss': 1.474, 'learning_rate': 1.1037197936464839e-05, 'epoch': 7.79}\n",
      "{'loss': 1.4648, 'learning_rate': 1.0969318490361118e-05, 'epoch': 7.81}\n",
      "{'loss': 1.4559, 'learning_rate': 1.09014390442574e-05, 'epoch': 7.82}\n",
      "{'loss': 1.5283, 'learning_rate': 1.083355959815368e-05, 'epoch': 7.83}\n",
      "{'loss': 1.4375, 'learning_rate': 1.076568015204996e-05, 'epoch': 7.85}\n",
      "{'loss': 1.5555, 'learning_rate': 1.069780070594624e-05, 'epoch': 7.86}\n",
      "{'loss': 1.4641, 'learning_rate': 1.062992125984252e-05, 'epoch': 7.87}\n",
      "{'loss': 1.4581, 'learning_rate': 1.05620418137388e-05, 'epoch': 7.89}\n",
      "{'loss': 1.4199, 'learning_rate': 1.049416236763508e-05, 'epoch': 7.9}\n",
      "{'loss': 1.4446, 'learning_rate': 1.0426282921531361e-05, 'epoch': 7.91}\n",
      "{'loss': 1.5118, 'learning_rate': 1.0358403475427642e-05, 'epoch': 7.93}\n",
      "{'loss': 1.5591, 'learning_rate': 1.0290524029323921e-05, 'epoch': 7.94}\n",
      "{'loss': 1.523, 'learning_rate': 1.0222644583220202e-05, 'epoch': 7.96}\n",
      "{'loss': 1.4743, 'learning_rate': 1.0154765137116481e-05, 'epoch': 7.97}\n",
      "{'loss': 1.5313, 'learning_rate': 1.0086885691012762e-05, 'epoch': 7.98}\n",
      "{'loss': 1.4961, 'learning_rate': 1.0019006244909041e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203bbf9ca18a471cacf287fdff920f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.615966796875, 'eval_rouge1': 44.2972, 'eval_rouge2': 19.9653, 'eval_rougeL': 36.8154, 'eval_rougeLsum': 40.4101, 'eval_gen_len': 16.746031746031747, 'eval_runtime': 53.6182, 'eval_samples_per_second': 15.275, 'eval_steps_per_second': 3.823, 'epoch': 8.0}\n",
      "{'loss': 1.4716, 'learning_rate': 9.951126798805322e-06, 'epoch': 8.01}\n",
      "{'loss': 1.4544, 'learning_rate': 9.883247352701603e-06, 'epoch': 8.02}\n",
      "{'loss': 1.5091, 'learning_rate': 9.815367906597884e-06, 'epoch': 8.04}\n",
      "{'loss': 1.4929, 'learning_rate': 9.747488460494163e-06, 'epoch': 8.05}\n",
      "{'loss': 1.4317, 'learning_rate': 9.679609014390444e-06, 'epoch': 8.06}\n",
      "{'loss': 1.4626, 'learning_rate': 9.611729568286723e-06, 'epoch': 8.08}\n",
      "{'loss': 1.496, 'learning_rate': 9.543850122183004e-06, 'epoch': 8.09}\n",
      "{'loss': 1.4512, 'learning_rate': 9.475970676079284e-06, 'epoch': 8.1}\n",
      "{'loss': 1.4381, 'learning_rate': 9.408091229975565e-06, 'epoch': 8.12}\n",
      "{'loss': 1.3879, 'learning_rate': 9.340211783871844e-06, 'epoch': 8.13}\n",
      "{'loss': 1.487, 'learning_rate': 9.272332337768125e-06, 'epoch': 8.15}\n",
      "{'loss': 1.4245, 'learning_rate': 9.204452891664404e-06, 'epoch': 8.16}\n",
      "{'loss': 1.4584, 'learning_rate': 9.136573445560685e-06, 'epoch': 8.17}\n",
      "{'loss': 1.438, 'learning_rate': 9.068693999456964e-06, 'epoch': 8.19}\n",
      "{'loss': 1.4426, 'learning_rate': 9.000814553353245e-06, 'epoch': 8.2}\n",
      "{'loss': 1.4216, 'learning_rate': 8.932935107249526e-06, 'epoch': 8.21}\n",
      "{'loss': 1.4766, 'learning_rate': 8.865055661145807e-06, 'epoch': 8.23}\n",
      "{'loss': 1.4588, 'learning_rate': 8.797176215042086e-06, 'epoch': 8.24}\n",
      "{'loss': 1.4713, 'learning_rate': 8.729296768938367e-06, 'epoch': 8.25}\n",
      "{'loss': 1.3914, 'learning_rate': 8.661417322834646e-06, 'epoch': 8.27}\n",
      "{'loss': 1.4418, 'learning_rate': 8.593537876730926e-06, 'epoch': 8.28}\n",
      "{'loss': 1.5124, 'learning_rate': 8.525658430627206e-06, 'epoch': 8.29}\n",
      "{'loss': 1.4939, 'learning_rate': 8.457778984523488e-06, 'epoch': 8.31}\n",
      "{'loss': 1.5653, 'learning_rate': 8.389899538419767e-06, 'epoch': 8.32}\n",
      "{'loss': 1.4781, 'learning_rate': 8.322020092316048e-06, 'epoch': 8.34}\n",
      "{'loss': 1.4447, 'learning_rate': 8.254140646212327e-06, 'epoch': 8.35}\n",
      "{'loss': 1.4201, 'learning_rate': 8.186261200108608e-06, 'epoch': 8.36}\n",
      "{'loss': 1.4481, 'learning_rate': 8.118381754004887e-06, 'epoch': 8.38}\n",
      "{'loss': 1.4493, 'learning_rate': 8.050502307901168e-06, 'epoch': 8.39}\n",
      "{'loss': 1.4727, 'learning_rate': 7.982622861797449e-06, 'epoch': 8.4}\n",
      "{'loss': 1.4861, 'learning_rate': 7.91474341569373e-06, 'epoch': 8.42}\n",
      "{'loss': 1.4667, 'learning_rate': 7.846863969590009e-06, 'epoch': 8.43}\n",
      "{'loss': 1.4867, 'learning_rate': 7.77898452348629e-06, 'epoch': 8.44}\n",
      "{'loss': 1.4725, 'learning_rate': 7.711105077382569e-06, 'epoch': 8.46}\n",
      "{'loss': 1.489, 'learning_rate': 7.64322563127885e-06, 'epoch': 8.47}\n",
      "{'loss': 1.4926, 'learning_rate': 7.575346185175129e-06, 'epoch': 8.48}\n",
      "{'loss': 1.4516, 'learning_rate': 7.50746673907141e-06, 'epoch': 8.5}\n",
      "{'loss': 1.4607, 'learning_rate': 7.439587292967689e-06, 'epoch': 8.51}\n",
      "{'loss': 1.5045, 'learning_rate': 7.37170784686397e-06, 'epoch': 8.53}\n",
      "{'loss': 1.4498, 'learning_rate': 7.30382840076025e-06, 'epoch': 8.54}\n",
      "{'loss': 1.4349, 'learning_rate': 7.235948954656531e-06, 'epoch': 8.55}\n",
      "{'loss': 1.4535, 'learning_rate': 7.16806950855281e-06, 'epoch': 8.57}\n",
      "{'loss': 1.4839, 'learning_rate': 7.100190062449092e-06, 'epoch': 8.58}\n",
      "{'loss': 1.5295, 'learning_rate': 7.032310616345371e-06, 'epoch': 8.59}\n",
      "{'loss': 1.5032, 'learning_rate': 6.964431170241652e-06, 'epoch': 8.61}\n",
      "{'loss': 1.5044, 'learning_rate': 6.896551724137932e-06, 'epoch': 8.62}\n",
      "{'loss': 1.4234, 'learning_rate': 6.8286722780342125e-06, 'epoch': 8.63}\n",
      "{'loss': 1.4531, 'learning_rate': 6.760792831930492e-06, 'epoch': 8.65}\n",
      "{'loss': 1.5211, 'learning_rate': 6.692913385826772e-06, 'epoch': 8.66}\n",
      "{'loss': 1.4708, 'learning_rate': 6.625033939723052e-06, 'epoch': 8.67}\n",
      "{'loss': 1.4977, 'learning_rate': 6.557154493619333e-06, 'epoch': 8.69}\n",
      "{'loss': 1.5052, 'learning_rate': 6.489275047515612e-06, 'epoch': 8.7}\n",
      "{'loss': 1.4904, 'learning_rate': 6.421395601411893e-06, 'epoch': 8.72}\n",
      "{'loss': 1.525, 'learning_rate': 6.353516155308173e-06, 'epoch': 8.73}\n",
      "{'loss': 1.4466, 'learning_rate': 6.285636709204454e-06, 'epoch': 8.74}\n",
      "{'loss': 1.4439, 'learning_rate': 6.217757263100733e-06, 'epoch': 8.76}\n",
      "{'loss': 1.4747, 'learning_rate': 6.149877816997014e-06, 'epoch': 8.77}\n",
      "{'loss': 1.4888, 'learning_rate': 6.081998370893294e-06, 'epoch': 8.78}\n",
      "{'loss': 1.4945, 'learning_rate': 6.014118924789574e-06, 'epoch': 8.8}\n",
      "{'loss': 1.4335, 'learning_rate': 5.946239478685854e-06, 'epoch': 8.81}\n",
      "{'loss': 1.452, 'learning_rate': 5.878360032582135e-06, 'epoch': 8.82}\n",
      "{'loss': 1.4778, 'learning_rate': 5.8104805864784146e-06, 'epoch': 8.84}\n",
      "{'loss': 1.5235, 'learning_rate': 5.7426011403746945e-06, 'epoch': 8.85}\n",
      "{'loss': 1.4936, 'learning_rate': 5.674721694270975e-06, 'epoch': 8.87}\n",
      "{'loss': 1.4864, 'learning_rate': 5.606842248167255e-06, 'epoch': 8.88}\n",
      "{'loss': 1.5075, 'learning_rate': 5.538962802063535e-06, 'epoch': 8.89}\n",
      "{'loss': 1.4634, 'learning_rate': 5.471083355959815e-06, 'epoch': 8.91}\n",
      "{'loss': 1.4842, 'learning_rate': 5.403203909856096e-06, 'epoch': 8.92}\n",
      "{'loss': 1.3854, 'learning_rate': 5.335324463752376e-06, 'epoch': 8.93}\n",
      "{'loss': 1.4234, 'learning_rate': 5.267445017648656e-06, 'epoch': 8.95}\n",
      "{'loss': 1.5044, 'learning_rate': 5.199565571544936e-06, 'epoch': 8.96}\n",
      "{'loss': 1.4862, 'learning_rate': 5.131686125441217e-06, 'epoch': 8.97}\n",
      "{'loss': 1.4745, 'learning_rate': 5.063806679337497e-06, 'epoch': 8.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502c3a7e080f45f0a3cae174df32332c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6165939569473267, 'eval_rouge1': 44.1914, 'eval_rouge2': 19.9611, 'eval_rougeL': 36.6953, 'eval_rougeLsum': 40.3145, 'eval_gen_len': 16.913308913308914, 'eval_runtime': 52.872, 'eval_samples_per_second': 15.49, 'eval_steps_per_second': 3.877, 'epoch': 9.0}\n",
      "{'loss': 1.4229, 'learning_rate': 4.995927233233777e-06, 'epoch': 9.0}\n",
      "{'loss': 1.4434, 'learning_rate': 4.9280477871300576e-06, 'epoch': 9.01}\n",
      "{'loss': 1.4977, 'learning_rate': 4.8601683410263375e-06, 'epoch': 9.03}\n",
      "{'loss': 1.4452, 'learning_rate': 4.7922888949226175e-06, 'epoch': 9.04}\n",
      "{'loss': 1.4682, 'learning_rate': 4.7244094488188975e-06, 'epoch': 9.06}\n",
      "{'loss': 1.4926, 'learning_rate': 4.656530002715178e-06, 'epoch': 9.07}\n",
      "{'loss': 1.4597, 'learning_rate': 4.588650556611458e-06, 'epoch': 9.08}\n",
      "{'loss': 1.4088, 'learning_rate': 4.520771110507738e-06, 'epoch': 9.1}\n",
      "{'loss': 1.5238, 'learning_rate': 4.452891664404018e-06, 'epoch': 9.11}\n",
      "{'loss': 1.4693, 'learning_rate': 4.385012218300299e-06, 'epoch': 9.12}\n",
      "{'loss': 1.4561, 'learning_rate': 4.317132772196579e-06, 'epoch': 9.14}\n",
      "{'loss': 1.4289, 'learning_rate': 4.249253326092859e-06, 'epoch': 9.15}\n",
      "{'loss': 1.4754, 'learning_rate': 4.18137387998914e-06, 'epoch': 9.16}\n",
      "{'loss': 1.3984, 'learning_rate': 4.11349443388542e-06, 'epoch': 9.18}\n",
      "{'loss': 1.5217, 'learning_rate': 4.0456149877817e-06, 'epoch': 9.19}\n",
      "{'loss': 1.4559, 'learning_rate': 3.97773554167798e-06, 'epoch': 9.2}\n",
      "{'loss': 1.4549, 'learning_rate': 3.9098560955742605e-06, 'epoch': 9.22}\n",
      "{'loss': 1.4197, 'learning_rate': 3.8419766494705405e-06, 'epoch': 9.23}\n",
      "{'loss': 1.4697, 'learning_rate': 3.7740972033668204e-06, 'epoch': 9.25}\n",
      "{'loss': 1.4439, 'learning_rate': 3.706217757263101e-06, 'epoch': 9.26}\n",
      "{'loss': 1.4952, 'learning_rate': 3.6383383111593812e-06, 'epoch': 9.27}\n",
      "{'loss': 1.4959, 'learning_rate': 3.570458865055661e-06, 'epoch': 9.29}\n",
      "{'loss': 1.4332, 'learning_rate': 3.5025794189519416e-06, 'epoch': 9.3}\n",
      "{'loss': 1.4942, 'learning_rate': 3.4346999728482216e-06, 'epoch': 9.31}\n",
      "{'loss': 1.4177, 'learning_rate': 3.366820526744502e-06, 'epoch': 9.33}\n",
      "{'loss': 1.4353, 'learning_rate': 3.298941080640782e-06, 'epoch': 9.34}\n",
      "{'loss': 1.375, 'learning_rate': 3.2310616345370623e-06, 'epoch': 9.35}\n",
      "{'loss': 1.4728, 'learning_rate': 3.1631821884333423e-06, 'epoch': 9.37}\n",
      "{'loss': 1.4019, 'learning_rate': 3.0953027423296227e-06, 'epoch': 9.38}\n",
      "{'loss': 1.4996, 'learning_rate': 3.027423296225903e-06, 'epoch': 9.39}\n",
      "{'loss': 1.4688, 'learning_rate': 2.959543850122183e-06, 'epoch': 9.41}\n",
      "{'loss': 1.4972, 'learning_rate': 2.8916644040184634e-06, 'epoch': 9.42}\n",
      "{'loss': 1.4608, 'learning_rate': 2.8237849579147434e-06, 'epoch': 9.44}\n",
      "{'loss': 1.4365, 'learning_rate': 2.755905511811024e-06, 'epoch': 9.45}\n",
      "{'loss': 1.4243, 'learning_rate': 2.6880260657073038e-06, 'epoch': 9.46}\n",
      "{'loss': 1.4523, 'learning_rate': 2.620146619603584e-06, 'epoch': 9.48}\n",
      "{'loss': 1.4059, 'learning_rate': 2.552267173499864e-06, 'epoch': 9.49}\n",
      "{'loss': 1.4482, 'learning_rate': 2.4843877273961445e-06, 'epoch': 9.5}\n",
      "{'loss': 1.4648, 'learning_rate': 2.416508281292425e-06, 'epoch': 9.52}\n",
      "{'loss': 1.4344, 'learning_rate': 2.348628835188705e-06, 'epoch': 9.53}\n",
      "{'loss': 1.4794, 'learning_rate': 2.2807493890849853e-06, 'epoch': 9.54}\n",
      "{'loss': 1.4739, 'learning_rate': 2.2128699429812653e-06, 'epoch': 9.56}\n",
      "{'loss': 1.4749, 'learning_rate': 2.1449904968775457e-06, 'epoch': 9.57}\n",
      "{'loss': 1.5323, 'learning_rate': 2.0771110507738256e-06, 'epoch': 9.58}\n",
      "{'loss': 1.4365, 'learning_rate': 2.009231604670106e-06, 'epoch': 9.6}\n",
      "{'loss': 1.4963, 'learning_rate': 1.941352158566386e-06, 'epoch': 9.61}\n",
      "{'loss': 1.4973, 'learning_rate': 1.8734727124626664e-06, 'epoch': 9.63}\n",
      "{'loss': 1.4294, 'learning_rate': 1.8055932663589466e-06, 'epoch': 9.64}\n",
      "{'loss': 1.4053, 'learning_rate': 1.7377138202552268e-06, 'epoch': 9.65}\n",
      "{'loss': 1.4302, 'learning_rate': 1.669834374151507e-06, 'epoch': 9.67}\n",
      "{'loss': 1.452, 'learning_rate': 1.6019549280477871e-06, 'epoch': 9.68}\n",
      "{'loss': 1.4196, 'learning_rate': 1.5340754819440673e-06, 'epoch': 9.69}\n",
      "{'loss': 1.4522, 'learning_rate': 1.4661960358403477e-06, 'epoch': 9.71}\n",
      "{'loss': 1.462, 'learning_rate': 1.3983165897366279e-06, 'epoch': 9.72}\n",
      "{'loss': 1.4085, 'learning_rate': 1.330437143632908e-06, 'epoch': 9.73}\n",
      "{'loss': 1.4198, 'learning_rate': 1.2625576975291882e-06, 'epoch': 9.75}\n",
      "{'loss': 1.4692, 'learning_rate': 1.1946782514254684e-06, 'epoch': 9.76}\n",
      "{'loss': 1.4189, 'learning_rate': 1.1267988053217486e-06, 'epoch': 9.77}\n",
      "{'loss': 1.4485, 'learning_rate': 1.0589193592180288e-06, 'epoch': 9.79}\n",
      "{'loss': 1.4908, 'learning_rate': 9.91039913114309e-07, 'epoch': 9.8}\n",
      "{'loss': 1.4066, 'learning_rate': 9.231604670105893e-07, 'epoch': 9.82}\n",
      "{'loss': 1.5338, 'learning_rate': 8.552810209068694e-07, 'epoch': 9.83}\n",
      "{'loss': 1.4644, 'learning_rate': 7.874015748031496e-07, 'epoch': 9.84}\n",
      "{'loss': 1.4824, 'learning_rate': 7.195221286994298e-07, 'epoch': 9.86}\n",
      "{'loss': 1.4141, 'learning_rate': 6.516426825957101e-07, 'epoch': 9.87}\n",
      "{'loss': 1.5403, 'learning_rate': 5.837632364919903e-07, 'epoch': 9.88}\n",
      "{'loss': 1.5056, 'learning_rate': 5.158837903882704e-07, 'epoch': 9.9}\n",
      "{'loss': 1.4852, 'learning_rate': 4.4800434428455063e-07, 'epoch': 9.91}\n",
      "{'loss': 1.4571, 'learning_rate': 3.8012489818083086e-07, 'epoch': 9.92}\n",
      "{'loss': 1.4645, 'learning_rate': 3.1224545207711105e-07, 'epoch': 9.94}\n",
      "{'loss': 1.4259, 'learning_rate': 2.443660059733913e-07, 'epoch': 9.95}\n",
      "{'loss': 1.4862, 'learning_rate': 1.7648655986967146e-07, 'epoch': 9.96}\n",
      "{'loss': 1.4177, 'learning_rate': 1.0860711376595167e-07, 'epoch': 9.98}\n",
      "{'loss': 1.4712, 'learning_rate': 4.072766766223188e-08, 'epoch': 9.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049b540c62244af89f04b06b464cb164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.617746114730835, 'eval_rouge1': 44.4606, 'eval_rouge2': 20.1139, 'eval_rougeL': 36.8539, 'eval_rougeLsum': 40.5396, 'eval_gen_len': 16.94871794871795, 'eval_runtime': 56.2279, 'eval_samples_per_second': 14.566, 'eval_steps_per_second': 3.646, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 6683.0116, 'train_samples_per_second': 22.044, 'train_steps_per_second': 5.511, 'train_loss': 1.5758347343757624, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=36830, training_loss=1.5758347343757624, metrics={'train_runtime': 6683.0116, 'train_samples_per_second': 22.044, 'train_steps_per_second': 5.511, 'train_loss': 1.5758347343757624, 'epoch': 10.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493eee709cad44138e281721052f2b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.3694512844085693,\n",
       " 'eval_rouge1': 47.5774,\n",
       " 'eval_rouge2': 24.1721,\n",
       " 'eval_rougeL': 40.1577,\n",
       " 'eval_rougeLsum': 43.7501,\n",
       " 'eval_gen_len': 17.024420024420024,\n",
       " 'eval_runtime': 127.8578,\n",
       " 'eval_samples_per_second': 6.406,\n",
       " 'eval_steps_per_second': 1.603,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert4rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
